{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to MkDocs For full documentation visit mkdocs.org . Commands mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit. Project layout mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Welcome to MkDocs"},{"location":"#welcome-to-mkdocs","text":"For full documentation visit mkdocs.org .","title":"Welcome to MkDocs"},{"location":"#commands","text":"mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit.","title":"Commands"},{"location":"#project-layout","text":"mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Project layout"},{"location":"git/","text":"GIT useful steps Clone git clone [url] See all remote branches and upstream git branch -a git branch -vv Create new branch in local git checkout -b branchname Go to remote branch git checkout --track origin/branchname Set upstream git checkout branchname git push -u origin/branchname for branch that alr exists git push -u origin branchname to push new branch to remote Cloning a single branch git clone --branch [branchname] --single-branch [remote-repo-url] Removing git from directory rm -rf .git Removing latest commit < not yet pushed > git reset HEAD^","title":"GIT useful steps"},{"location":"git/#git-useful-steps","text":"","title":"GIT useful steps"},{"location":"git/#clone","text":"git clone [url]","title":"Clone"},{"location":"git/#see-all-remote-branches-and-upstream","text":"git branch -a git branch -vv","title":"See all remote branches and upstream"},{"location":"git/#create-new-branch-in-local","text":"git checkout -b branchname","title":"Create new branch in local"},{"location":"git/#go-to-remote-branch","text":"git checkout --track origin/branchname","title":"Go to remote branch"},{"location":"git/#set-upstream","text":"git checkout branchname git push -u origin/branchname for branch that alr exists git push -u origin branchname to push new branch to remote","title":"Set upstream"},{"location":"git/#cloning-a-single-branch","text":"git clone --branch [branchname] --single-branch [remote-repo-url]","title":"Cloning a single branch"},{"location":"git/#removing-git-from-directory","text":"rm -rf .git","title":"Removing git from directory"},{"location":"git/#removing-latest-commit-not-yet-pushed","text":"git reset HEAD^","title":"Removing latest commit &lt; not yet pushed &gt;"},{"location":"gitlab_CI/","text":"Example of deploying to aws ECR from a base docker image This is an example code used to deploy to ECR from a base docker image. The goal is to first test if the streamlit demo site is running. Upon success , build a new docker image every time there is changes to the demo site , and only when the changes are commited in a merge request to master. This new image is then pushed to a ECR repository , if the repo does not exist, it will create it then add the image in. deploy-demo: stage: deploy image: docker # Base image which gitlab Ci runs first services: - docker:dind # uses docker in docker service in order to build docker files variables: FULL_IMAGE_NAME: demosite-$IMAGE_NAME-$CI_PROJECT_ID before_script: - apk update # for alpine linux based image, which docker is . - apk upgrade - apk add curl bash # install curl and bash which is required for the below script - sh ci/install-aws_cli2.sh # Script to install AWS CLI for this docker image. script: - cd ci - bash deploy-demo.sh #run deploy -demo script rules: - if: '$CI_PIPELINE_SOURCE == \"merge_request_event\" && $CI_MERGE_REQUEST_TARGET_BRANCH_NAME == \"master\"' ## runs when commit is a merge request into master changes: - project/demo/* ## and only if there are any change to files inside project / demo when: always #!/bin/bash # build container echo \"building docker container\" cd .. cd project/demo docker build --tag $FULL_IMAGE_NAME . ## Creating docker image docker run -d -p 8501:8501 --name $FULL_IMAGE_NAME $FULL_IMAGE_NAME ## running the docker image , which in this case is the streamlit app . # check streamlit server has started time_elapsed=1 while true; do echo \"waiting streamlit server to start... $time_elapsed sec\" content=$(curl -s -w \"%{http_code}\" http://docker:8501) statuscode=\"${content:(-3)}\" if [ $statuscode -gt 299 ] then echo \"streamlit Server Error: $statuscode\" echo \"Error Msg: $content\" exit 1 elif [[ $statuscode == \"200\" ]] then echo -e \"streamlit Server Launched\\n\" break fi if [[ $time_elapsed == '10' ]] then docker logs $FULL_IMAGE_NAME exit 1 fi sleep 1 time_elapsed=$((time_elapsed + 1)) done ## Pushing image to AWS ECR echo \"Checking if repository exists. If it does not exist , creating repository..\" aws ecr describe-repositories --repository-names ${FULL_IMAGE_NAME} || aws ecr create-repository --repository-name ${FULL_IMAGE_NAME} # Check list of all repos in the ECR. aws ecr get-login-password --region $AWS_DEFAULT_REGION | docker login --username AWS --password-stdin $DOCKER_REGISTRY # login to aws ECR docker images docker tag ${FULL_IMAGE_NAME} $DOCKER_REGISTRY/$FULL_IMAGE_NAME #tag the image echo \"Pushing Image to ${FULL_IMAGE_NAME} repository\" docker push $DOCKER_REGISTRY/$FULL_IMAGE_NAME:latest # push image to ECR aws ecr describe-images --repository-name $FULL_IMAGE_NAME # describe the image to check if exists","title":"Example of deploying to aws ECR from a base docker image"},{"location":"gitlab_CI/#example-of-deploying-to-aws-ecr-from-a-base-docker-image","text":"This is an example code used to deploy to ECR from a base docker image. The goal is to first test if the streamlit demo site is running. Upon success , build a new docker image every time there is changes to the demo site , and only when the changes are commited in a merge request to master. This new image is then pushed to a ECR repository , if the repo does not exist, it will create it then add the image in. deploy-demo: stage: deploy image: docker # Base image which gitlab Ci runs first services: - docker:dind # uses docker in docker service in order to build docker files variables: FULL_IMAGE_NAME: demosite-$IMAGE_NAME-$CI_PROJECT_ID before_script: - apk update # for alpine linux based image, which docker is . - apk upgrade - apk add curl bash # install curl and bash which is required for the below script - sh ci/install-aws_cli2.sh # Script to install AWS CLI for this docker image. script: - cd ci - bash deploy-demo.sh #run deploy -demo script rules: - if: '$CI_PIPELINE_SOURCE == \"merge_request_event\" && $CI_MERGE_REQUEST_TARGET_BRANCH_NAME == \"master\"' ## runs when commit is a merge request into master changes: - project/demo/* ## and only if there are any change to files inside project / demo when: always #!/bin/bash # build container echo \"building docker container\" cd .. cd project/demo docker build --tag $FULL_IMAGE_NAME . ## Creating docker image docker run -d -p 8501:8501 --name $FULL_IMAGE_NAME $FULL_IMAGE_NAME ## running the docker image , which in this case is the streamlit app . # check streamlit server has started time_elapsed=1 while true; do echo \"waiting streamlit server to start... $time_elapsed sec\" content=$(curl -s -w \"%{http_code}\" http://docker:8501) statuscode=\"${content:(-3)}\" if [ $statuscode -gt 299 ] then echo \"streamlit Server Error: $statuscode\" echo \"Error Msg: $content\" exit 1 elif [[ $statuscode == \"200\" ]] then echo -e \"streamlit Server Launched\\n\" break fi if [[ $time_elapsed == '10' ]] then docker logs $FULL_IMAGE_NAME exit 1 fi sleep 1 time_elapsed=$((time_elapsed + 1)) done ## Pushing image to AWS ECR echo \"Checking if repository exists. If it does not exist , creating repository..\" aws ecr describe-repositories --repository-names ${FULL_IMAGE_NAME} || aws ecr create-repository --repository-name ${FULL_IMAGE_NAME} # Check list of all repos in the ECR. aws ecr get-login-password --region $AWS_DEFAULT_REGION | docker login --username AWS --password-stdin $DOCKER_REGISTRY # login to aws ECR docker images docker tag ${FULL_IMAGE_NAME} $DOCKER_REGISTRY/$FULL_IMAGE_NAME #tag the image echo \"Pushing Image to ${FULL_IMAGE_NAME} repository\" docker push $DOCKER_REGISTRY/$FULL_IMAGE_NAME:latest # push image to ECR aws ecr describe-images --repository-name $FULL_IMAGE_NAME # describe the image to check if exists","title":"Example of deploying to aws ECR from a base docker image"},{"location":"markdown-cheat-sheet/","text":"Markdown Cheat Sheet Thanks for visiting The Markdown Guide ! This Markdown cheat sheet provides a quick overview of all the Markdown syntax elements. It can\u2019t cover every edge case, so if you need more information about any of these elements, refer to the reference guides for basic syntax and extended syntax . Basic Syntax These are the elements outlined in John Gruber\u2019s original design document. All Markdown applications support these elements. Heading H1 H2 H3 Bold bold text Italic italicized text Blockquote blockquote Ordered List First item Second item Third item Unordered List First item Second item Third item Code code Horizontal Rule Link title Image Extended Syntax These elements extend the basic syntax by adding additional features. Not all Markdown applications support these elements. Table Syntax Description Header Title Paragraph Text Fenced Code Block { \"firstName\": \"John\", \"lastName\": \"Smith\", \"age\": 25 } Footnote Here's a sentence with a footnote. [^1] [^1]: This is the footnote. Heading ID My Great Heading {#custom-id} Definition List term : definition Strikethrough ~~The world is flat.~~ Task List [x] Write the press release [ ] Update the website [ ] Contact the media","title":"Markdown Cheat Sheet"},{"location":"markdown-cheat-sheet/#markdown-cheat-sheet","text":"Thanks for visiting The Markdown Guide ! This Markdown cheat sheet provides a quick overview of all the Markdown syntax elements. It can\u2019t cover every edge case, so if you need more information about any of these elements, refer to the reference guides for basic syntax and extended syntax .","title":"Markdown Cheat Sheet"},{"location":"markdown-cheat-sheet/#basic-syntax","text":"These are the elements outlined in John Gruber\u2019s original design document. All Markdown applications support these elements.","title":"Basic Syntax"},{"location":"markdown-cheat-sheet/#heading","text":"","title":"Heading"},{"location":"markdown-cheat-sheet/#h1","text":"","title":"H1"},{"location":"markdown-cheat-sheet/#h2","text":"","title":"H2"},{"location":"markdown-cheat-sheet/#h3","text":"","title":"H3"},{"location":"markdown-cheat-sheet/#bold","text":"bold text","title":"Bold"},{"location":"markdown-cheat-sheet/#italic","text":"italicized text","title":"Italic"},{"location":"markdown-cheat-sheet/#blockquote","text":"blockquote","title":"Blockquote"},{"location":"markdown-cheat-sheet/#ordered-list","text":"First item Second item Third item","title":"Ordered List"},{"location":"markdown-cheat-sheet/#unordered-list","text":"First item Second item Third item","title":"Unordered List"},{"location":"markdown-cheat-sheet/#code","text":"code","title":"Code"},{"location":"markdown-cheat-sheet/#horizontal-rule","text":"","title":"Horizontal Rule"},{"location":"markdown-cheat-sheet/#link","text":"title","title":"Link"},{"location":"markdown-cheat-sheet/#image","text":"","title":"Image"},{"location":"markdown-cheat-sheet/#extended-syntax","text":"These elements extend the basic syntax by adding additional features. Not all Markdown applications support these elements.","title":"Extended Syntax"},{"location":"markdown-cheat-sheet/#table","text":"Syntax Description Header Title Paragraph Text","title":"Table"},{"location":"markdown-cheat-sheet/#fenced-code-block","text":"{ \"firstName\": \"John\", \"lastName\": \"Smith\", \"age\": 25 }","title":"Fenced Code Block"},{"location":"markdown-cheat-sheet/#footnote","text":"Here's a sentence with a footnote. [^1] [^1]: This is the footnote.","title":"Footnote"},{"location":"markdown-cheat-sheet/#heading-id","text":"","title":"Heading ID"},{"location":"markdown-cheat-sheet/#my-great-heading-custom-id","text":"","title":"My Great Heading {#custom-id}"},{"location":"markdown-cheat-sheet/#definition-list","text":"term : definition","title":"Definition List"},{"location":"markdown-cheat-sheet/#strikethrough","text":"~~The world is flat.~~","title":"Strikethrough"},{"location":"markdown-cheat-sheet/#task-list","text":"[x] Write the press release [ ] Update the website [ ] Contact the media","title":"Task List"},{"location":"nlp/","text":"General NLP steps 1. Explore the dataset Look through the data set in order to see how it is formatted , the labels and contents. Can do so using for loop for first few data points. messages.head() for mess_no, message in enumerate(messages[:10]): print(mess_no,message) print('\\n') 2. Labelling In the case of the spam/ham messages , the label of whether or not it is spam / ham is at the front of the message , seperated by a tab. 0 ham Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat... We would need to put the label in a different column of the pd data frame. messages = pd.read_csv('smsspamcollection/SMSSpamCollection',sep='\\t',names=['label','message']) Another useful attribute that might contribute could be length of message. To add that we add the end result would be a neatly seperated table with the label as different rows. messages['length'] = messages['message'].apply(len) label message length 0 ham Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat... 111 1 ham Ok lar... Joking wif u oni... 29 2 spam Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's 155 3 ham U dun say so early hor... U c already then say... 49 4 ham Nah I don't think he goes to usf, he lives around here though 61 Import relevant libraries import string mess = 'Sample message! Notice: it has punctuation.' # Check characters to see if they are in punctuation nopunc = [char for char in mess if char not in string.punctuation] # Join the characters again to form the string. nopunc = ''.join(nopunc) ## The join() method takes all items in an iterable and joins them into one string. the space infront of the join is what seperates the diff words. Stopwords stopwords are very common words that they do not help distinguish one source of text from the other. from nltk.corpus import stopwords stopwords.words('english')[0:10] # Show some stop words First, we got to split the text up to individual words again. Next, we repeat the same function as nopunc to remove stopwords. clean_mess = [word for word in nopunc.split() if word.lower() not in stopwords.words('english')] ## put in a list all words that are not in stopwords english. Function for text pre-processing def text_process(mess): \"\"\" Takes in a string of text, then performs the following: 1. Remove all punctuation 2. Remove all stopwords 3. Returns a list of the cleaned text \"\"\" # Check characters to see if they are in punctuation nopunc = [char for char in mess if char not in string.punctuation] # Join the characters again to form the string. nopunc = ''.join(nopunc) # Now just remove any stopwords return [word for word in nopunc.split() if word.lower() not in stopwords.words('english')] Tokenization Apply the function ( text_process ) to the messages in the message row : messages['message'].head(5).apply(text_process)","title":"General NLP steps"},{"location":"nlp/#general-nlp-steps","text":"","title":"General NLP steps"},{"location":"nlp/#1-explore-the-dataset","text":"Look through the data set in order to see how it is formatted , the labels and contents. Can do so using for loop for first few data points. messages.head() for mess_no, message in enumerate(messages[:10]): print(mess_no,message) print('\\n')","title":"1. Explore the dataset"},{"location":"nlp/#2-labelling","text":"In the case of the spam/ham messages , the label of whether or not it is spam / ham is at the front of the message , seperated by a tab. 0 ham Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat... We would need to put the label in a different column of the pd data frame. messages = pd.read_csv('smsspamcollection/SMSSpamCollection',sep='\\t',names=['label','message']) Another useful attribute that might contribute could be length of message. To add that we add the end result would be a neatly seperated table with the label as different rows. messages['length'] = messages['message'].apply(len) label message length 0 ham Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat... 111 1 ham Ok lar... Joking wif u oni... 29 2 spam Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's 155 3 ham U dun say so early hor... U c already then say... 49 4 ham Nah I don't think he goes to usf, he lives around here though 61","title":"2. Labelling"},{"location":"nlp/#import-relevant-libraries","text":"import string mess = 'Sample message! Notice: it has punctuation.' # Check characters to see if they are in punctuation nopunc = [char for char in mess if char not in string.punctuation] # Join the characters again to form the string. nopunc = ''.join(nopunc) ## The join() method takes all items in an iterable and joins them into one string. the space infront of the join is what seperates the diff words.","title":"Import relevant libraries"},{"location":"nlp/#stopwords","text":"stopwords are very common words that they do not help distinguish one source of text from the other. from nltk.corpus import stopwords stopwords.words('english')[0:10] # Show some stop words First, we got to split the text up to individual words again. Next, we repeat the same function as nopunc to remove stopwords. clean_mess = [word for word in nopunc.split() if word.lower() not in stopwords.words('english')] ## put in a list all words that are not in stopwords english.","title":"Stopwords"},{"location":"nlp/#function-for-text-pre-processing","text":"def text_process(mess): \"\"\" Takes in a string of text, then performs the following: 1. Remove all punctuation 2. Remove all stopwords 3. Returns a list of the cleaned text \"\"\" # Check characters to see if they are in punctuation nopunc = [char for char in mess if char not in string.punctuation] # Join the characters again to form the string. nopunc = ''.join(nopunc) # Now just remove any stopwords return [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]","title":"Function for text pre-processing"},{"location":"nlp/#tokenization","text":"Apply the function ( text_process ) to the messages in the message row : messages['message'].head(5).apply(text_process)","title":"Tokenization"},{"location":"nlp2/","text":"General NLP steps 1. Explore the dataset Look through the data set in order to see how it is formatted , the labels and contents. Can do so using for loop for first few data points. messages.head() for mess_no, message in enumerate(messages[:10]): print(mess_no,message) print('\\n') 2. Labelling In the case of the spam/ham messages , the label of whether or not it is spam / ham is at the front of the message , seperated by a tab. 0 ham Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat... We would need to put the label in a different column of the pd data frame. messages = pd.read_csv('smsspamcollection/SMSSpamCollection',sep='\\t',names=['label','message']) Another useful attribute that might contribute could be length of message. To add that we add the end result would be a neatly seperated table with the label as different rows. messages['length'] = messages['message'].apply(len) label message length 0 ham Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat... 111 1 ham Ok lar... Joking wif u oni... 29 2 spam Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's 155 3 ham U dun say so early hor... U c already then say... 49 4 ham Nah I don't think he goes to usf, he lives around here though 61 Import relevant libraries import string mess = 'Sample message! Notice: it has punctuation.' # Check characters to see if they are in punctuation nopunc = [char for char in mess if char not in string.punctuation] # Join the characters again to form the string. nopunc = ''.join(nopunc) ## The join() method takes all items in an iterable and joins them into one string. the space infront of the join is what seperates the diff words. Stopwords stopwords are very common words that they do not help distinguish one source of text from the other. from nltk.corpus import stopwords stopwords.words('english')[0:10] # Show some stop words First, we got to split the text up to individual words again. Next, we repeat the same function as nopunc to remove stopwords. clean_mess = [word for word in nopunc.split() if word.lower() not in stopwords.words('english')] ## put in a list all words that are not in stopwords english. Function for text pre-processing def text_process(mess): \"\"\" Takes in a string of text, then performs the following: 1. Remove all punctuation 2. Remove all stopwords 3. Returns a list of the cleaned text \"\"\" # Check characters to see if they are in punctuation nopunc = [char for char in mess if char not in string.punctuation] # Join the characters again to form the string. nopunc = ''.join(nopunc) # Now just remove any stopwords return [word for word in nopunc.split() if word.lower() not in stopwords.words('english')] Tokenization Apply the function ( text_process ) to the messages in the message row : messages['message'].head(5).apply(text_process)","title":"General NLP steps"},{"location":"nlp2/#general-nlp-steps","text":"","title":"General NLP steps"},{"location":"nlp2/#1-explore-the-dataset","text":"Look through the data set in order to see how it is formatted , the labels and contents. Can do so using for loop for first few data points. messages.head() for mess_no, message in enumerate(messages[:10]): print(mess_no,message) print('\\n')","title":"1. Explore the dataset"},{"location":"nlp2/#2-labelling","text":"In the case of the spam/ham messages , the label of whether or not it is spam / ham is at the front of the message , seperated by a tab. 0 ham Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat... We would need to put the label in a different column of the pd data frame. messages = pd.read_csv('smsspamcollection/SMSSpamCollection',sep='\\t',names=['label','message']) Another useful attribute that might contribute could be length of message. To add that we add the end result would be a neatly seperated table with the label as different rows. messages['length'] = messages['message'].apply(len) label message length 0 ham Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat... 111 1 ham Ok lar... Joking wif u oni... 29 2 spam Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's 155 3 ham U dun say so early hor... U c already then say... 49 4 ham Nah I don't think he goes to usf, he lives around here though 61","title":"2. Labelling"},{"location":"nlp2/#import-relevant-libraries","text":"import string mess = 'Sample message! Notice: it has punctuation.' # Check characters to see if they are in punctuation nopunc = [char for char in mess if char not in string.punctuation] # Join the characters again to form the string. nopunc = ''.join(nopunc) ## The join() method takes all items in an iterable and joins them into one string. the space infront of the join is what seperates the diff words.","title":"Import relevant libraries"},{"location":"nlp2/#stopwords","text":"stopwords are very common words that they do not help distinguish one source of text from the other. from nltk.corpus import stopwords stopwords.words('english')[0:10] # Show some stop words First, we got to split the text up to individual words again. Next, we repeat the same function as nopunc to remove stopwords. clean_mess = [word for word in nopunc.split() if word.lower() not in stopwords.words('english')] ## put in a list all words that are not in stopwords english.","title":"Stopwords"},{"location":"nlp2/#function-for-text-pre-processing","text":"def text_process(mess): \"\"\" Takes in a string of text, then performs the following: 1. Remove all punctuation 2. Remove all stopwords 3. Returns a list of the cleaned text \"\"\" # Check characters to see if they are in punctuation nopunc = [char for char in mess if char not in string.punctuation] # Join the characters again to form the string. nopunc = ''.join(nopunc) # Now just remove any stopwords return [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]","title":"Function for text pre-processing"},{"location":"nlp2/#tokenization","text":"Apply the function ( text_process ) to the messages in the message row : messages['message'].head(5).apply(text_process)","title":"Tokenization"},{"location":"python/","text":"Some useful python commands to help with ML","title":"Some useful python commands to help with ML"},{"location":"python/#some-useful-python-commands-to-help-with-ml","text":"","title":"Some useful python commands to help with ML"},{"location":"terraform/","text":"Sample Terraform script This is an example gitlab ci script which runs a whole terraform process, from creating ecs and ecr , to deploying a demo website via streamlit. The variables needed in env variables are : IMAGE_NAME AWS_ACCESS_KEY_ID AWS_SECRET_ACCESS_KEY AWS_DEFAULT_REGION variables: # ask cloud engineer DEMOSITE_DOCKER_CONTAINER_PORT: 8501 DOCKER_REGISTRY: example.ap-southeast-1.amazonaws.com DOCKER_HOST: tcp://docker:2375 S3_BUCKET_NAME: \"examples3bucket\" TERRAFORM_DIR: \"TERRAFORM_INFRA\" ECS_CLUSTER_NAME: \"examplecluster\" demosite-staging-terraform-plan-apply: stage: staging-build image: name: zenika/terraform-aws-cli:latest entrypoint: - \"/usr/bin/env\" - \"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\" script: - bash ci/demo-terraform.sh dev only: refs: - master changes: - project/demo/* demosite-staging-deploy: stage: staging-deploy image: name: amazon/aws-cli entrypoint: [\"\"] services: - docker:dind before_script: - amazon-linux-extras install docker script: - cd ci - bash demo-deploy.sh dev only: refs: - master changes: - project/demo/* demosite-prod-terraform-apply: stage: prod-build image: name: zenika/terraform-aws-cli:latest entrypoint: - \"/usr/bin/env\" - \"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\" script: - bash ci/demo-terraform.sh prod - bash ci/demo-terraform.sh dev destroy only: refs: - master changes: - project/demo/* when: manual demosite-prod-deploy: stage: prod-deploy needs: [\"demosite-prod-terraform-apply\"] image: name: amazon/aws-cli entrypoint: [\"\"] services: - docker:dind before_script: - amazon-linux-extras install docker script: - cd ci - bash demo-deploy.sh prod only: refs: - master changes: - project/demo/* # ############################################## Stages There are 3 main stages to terraform ci. Plan Apply Destroy Common code for all 3 stages echo $IMAGE_NAME$suffix aws s3 cp s3://$S3_BUCKET_NAME/TERRAFORM_INFRA \"TERRAFORM_INFRA\" --recursive --exclude \".sh\" --exclude \".md\" ## copies needed files from s3 bucket [terraform infra] cd $TERRAFORM_DIR/$folder ## ******Creating relevant config files with variables populated by environment variables in gitlab ************** echo 'key=\"PROD/APP/'$IMAGE_NAME$suffix'.dsldemo.site.tfstate\"' > app-prod.config echo 'bucket=\"terraform-fargate-cluster\"' >> app-prod.config echo 'region=\"ap-southeast-1\"' >> app-prod.config awk '!/ecs_service_name/' production.tfvars > tmpfile && mv tmpfile production.tfvars awk '!/environment/' production.tfvars > tmpfile && mv tmpfile production.tfvars awk '!/docker_container_port/' production.tfvars > tmpfile && mv tmpfile production.tfvars echo \"ecs_service_name = \\\"$IMAGE_NAME$suffix\\\"\" >> production.tfvars echo \"environment = \\\"$folder\\\"\" >> production.tfvars echo \"docker_container_port = $DEMOSITE_DOCKER_CONTAINER_PORT\" >> production.tfvars cat app-prod.config cat production.tfvars ##***************************************************************************************************************** terraform init -backend-config=app-prod.config ## initialise terraform with the config files Plan image: name: zenika/terraform-aws-cli:latest entrypoint: - \"/usr/bin/env\" - \"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\" - \"AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}\" - \"AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}\" The image used is zenika/terraform-aws-cli, it has terraform with the latest aws-cli command line installed in it. This is to facilitate the creation of the ECR and ECS, which will both require login to be done. terraform plan -var-file=production.tfvars -out \"planfile_dev\" Apply terraform apply -var-file=production.tfvars --auto-approve echo \"Terraform Apply >> done\" This creates the relevant aws ecr and ecs services, as specified in the config files. Destroy terraform destroy -var-file=production.tfvars --auto-approve echo \"Terraform Destroy Plan >> done\" exit 0 This destroys the terraform infrastructure as specified in the config file, the aws ecr and ecs. Deploying streamlit demosite aws ecr get-login-password | docker login --username AWS --password-stdin $DOCKER_REGISTRY docker push $DOCKER_REGISTRY/$ECS_CLUSTER_NAME-$IMAGE_NAME$suffix:v1 aws ecs update-service --cluster $ECS_CLUSTER_NAME --service $IMAGE_NAME$suffix --force-new-deployment --region $AWS_DEFAULT_REGION This is used to deploy a docker image, in this case the demosite, to the aws ecr and ecs.","title":"Sample Terraform script"},{"location":"terraform/#sample-terraform-script","text":"This is an example gitlab ci script which runs a whole terraform process, from creating ecs and ecr , to deploying a demo website via streamlit. The variables needed in env variables are : IMAGE_NAME AWS_ACCESS_KEY_ID AWS_SECRET_ACCESS_KEY AWS_DEFAULT_REGION variables: # ask cloud engineer DEMOSITE_DOCKER_CONTAINER_PORT: 8501 DOCKER_REGISTRY: example.ap-southeast-1.amazonaws.com DOCKER_HOST: tcp://docker:2375 S3_BUCKET_NAME: \"examples3bucket\" TERRAFORM_DIR: \"TERRAFORM_INFRA\" ECS_CLUSTER_NAME: \"examplecluster\" demosite-staging-terraform-plan-apply: stage: staging-build image: name: zenika/terraform-aws-cli:latest entrypoint: - \"/usr/bin/env\" - \"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\" script: - bash ci/demo-terraform.sh dev only: refs: - master changes: - project/demo/* demosite-staging-deploy: stage: staging-deploy image: name: amazon/aws-cli entrypoint: [\"\"] services: - docker:dind before_script: - amazon-linux-extras install docker script: - cd ci - bash demo-deploy.sh dev only: refs: - master changes: - project/demo/* demosite-prod-terraform-apply: stage: prod-build image: name: zenika/terraform-aws-cli:latest entrypoint: - \"/usr/bin/env\" - \"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\" script: - bash ci/demo-terraform.sh prod - bash ci/demo-terraform.sh dev destroy only: refs: - master changes: - project/demo/* when: manual demosite-prod-deploy: stage: prod-deploy needs: [\"demosite-prod-terraform-apply\"] image: name: amazon/aws-cli entrypoint: [\"\"] services: - docker:dind before_script: - amazon-linux-extras install docker script: - cd ci - bash demo-deploy.sh prod only: refs: - master changes: - project/demo/* # ##############################################","title":"Sample Terraform script"},{"location":"terraform/#stages","text":"There are 3 main stages to terraform ci. Plan Apply Destroy","title":"Stages"},{"location":"terraform/#common-code-for-all-3-stages","text":"echo $IMAGE_NAME$suffix aws s3 cp s3://$S3_BUCKET_NAME/TERRAFORM_INFRA \"TERRAFORM_INFRA\" --recursive --exclude \".sh\" --exclude \".md\" ## copies needed files from s3 bucket [terraform infra] cd $TERRAFORM_DIR/$folder ## ******Creating relevant config files with variables populated by environment variables in gitlab ************** echo 'key=\"PROD/APP/'$IMAGE_NAME$suffix'.dsldemo.site.tfstate\"' > app-prod.config echo 'bucket=\"terraform-fargate-cluster\"' >> app-prod.config echo 'region=\"ap-southeast-1\"' >> app-prod.config awk '!/ecs_service_name/' production.tfvars > tmpfile && mv tmpfile production.tfvars awk '!/environment/' production.tfvars > tmpfile && mv tmpfile production.tfvars awk '!/docker_container_port/' production.tfvars > tmpfile && mv tmpfile production.tfvars echo \"ecs_service_name = \\\"$IMAGE_NAME$suffix\\\"\" >> production.tfvars echo \"environment = \\\"$folder\\\"\" >> production.tfvars echo \"docker_container_port = $DEMOSITE_DOCKER_CONTAINER_PORT\" >> production.tfvars cat app-prod.config cat production.tfvars ##***************************************************************************************************************** terraform init -backend-config=app-prod.config ## initialise terraform with the config files","title":"Common code for all 3 stages"},{"location":"terraform/#plan","text":"image: name: zenika/terraform-aws-cli:latest entrypoint: - \"/usr/bin/env\" - \"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\" - \"AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}\" - \"AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}\" The image used is zenika/terraform-aws-cli, it has terraform with the latest aws-cli command line installed in it. This is to facilitate the creation of the ECR and ECS, which will both require login to be done. terraform plan -var-file=production.tfvars -out \"planfile_dev\"","title":"Plan"},{"location":"terraform/#apply","text":"terraform apply -var-file=production.tfvars --auto-approve echo \"Terraform Apply >> done\" This creates the relevant aws ecr and ecs services, as specified in the config files.","title":"Apply"},{"location":"terraform/#destroy","text":"terraform destroy -var-file=production.tfvars --auto-approve echo \"Terraform Destroy Plan >> done\" exit 0 This destroys the terraform infrastructure as specified in the config file, the aws ecr and ecs.","title":"Destroy"},{"location":"terraform/#deploying-streamlit-demosite","text":"aws ecr get-login-password | docker login --username AWS --password-stdin $DOCKER_REGISTRY docker push $DOCKER_REGISTRY/$ECS_CLUSTER_NAME-$IMAGE_NAME$suffix:v1 aws ecs update-service --cluster $ECS_CLUSTER_NAME --service $IMAGE_NAME$suffix --force-new-deployment --region $AWS_DEFAULT_REGION This is used to deploy a docker image, in this case the demosite, to the aws ecr and ecs.","title":"Deploying streamlit demosite"}]}